export const metadata = { sidebar_position: 10, title: "üî¥ Calibration des LLMs" };

# üî¥ Calibration des LLMs

Il est possible de contrecarrer certains biais que pr√©sentent les LLMs via la calibration des **distributions de sortie** (@zhao2021calibrate).

**Que signifie exactement calibrer une distribution de sortie ?**

Parcourons un exemple rapide : Supposons que nous avons une t√¢che d'<Term term="sentiment analysis">analyse de sentiment</Term> avec deux √©tiquettes possibles, `Positive` et `Negative`.
Consid√©rons ce qui se passe lorsque le <Term term="LLM">LLM</Term> re√ßoit l'invite `Input: nothing Sentiment: `.
Cette entr√©e ne contient aucun _contexte_ que le LLM peut utiliser pour faire une pr√©diction de sentiment, elle est donc appel√©e entr√©e **sans contexte**.

Puisque `nothing` n'est ni un concept positif ni n√©gatif, nous nous attendrions √† ce que le LLM produise une probabilit√© d'environ 0,5 pour `Positive` et `Negative`. Cependant, souvent (et pour cet exemple) ce ne sera pas le cas.

```
p("Positive" | "Input: nothing Sentiment:") = 0,9

p("Negative" | "Input: nothing Sentiment:") = 0,1
```

√âtant donn√© ces probabilit√©s d'√©tiquettes pour une entr√©e sans contexte, nous savons que la **distribution de sortie** du LLM est probablement biais√©e vers l'√©tiquette `Positive`. Cela peut amener le LLM √† favoriser `Positive` pour toutes les entr√©es, m√™me si l'entr√©e n'est pas r√©ellement positive.

Si nous pouvons d'une mani√®re ou d'une autre **calibrer** la distribution de sortie, de sorte que les entr√©es sans contexte se voient attribuer une probabilit√© de 0,5 pour `Positive` et `Negative`, alors nous pouvons souvent √©liminer le biais vers `Positive` et le LLM sera plus fiable √† la fois sur les entr√©es sans contexte et les entr√©es avec contexte.

## Solution non technique

Une solution non technique √† ce probl√®me consiste simplement √† fournir quelques exemples o√π les exemples sans contexte se voient effectivement attribuer une probabilit√© de 0,5 pour `Positive` et `Negative`.

Par exemple, nous pourrions fournir les exemples suivants qui montrent chaque exemple sans contexte class√© √† la fois comme `Positive` et `Negative` :

```
Input: I hate this movie. Sentiment: Negative
Input: I love this movie. Sentiment: Positive
Input: N/A Sentiment: Positive
Input: N/A Sentiment: Negative
Input: nothing Sentiment: Positive
Input: nothing Sentiment: Negative
Input: I like eggs. Sentiment:
```

√Ä ma connaissance, cette solution n'a pas √©t√© explor√©e dans la litt√©rature, et je ne suis pas s√ªr de son efficacit√© en pratique. Cependant, c'est une solution simple qui d√©montre ce que la calibration essaie d'accomplir.

## Solution technique

Une autre solution est la **calibration contextuelle** (@zhao2021calibrate), o√π nous ajustons des param√®tres de calibration sp√©ciaux, qui garantissent que les entr√©es sans contexte comme `Input: nothing Sentiment: ` se voient attribuer une probabilit√© d'environ 0,5 pour les deux √©tiquettes.
Notez qu'en pratique, cette m√©thode effectue la calibration sur plusieurs entr√©es sans contexte diff√©rentes (par exemple, `Input: N/A Sentiment: `, `Input: [MASK] Sentiment: `). Elle fait la moyenne des param√®tres de calibration qui fonctionnent le mieux pour chaque entr√©e sans contexte afin de trouver les meilleurs param√®tres de calibration pour le LLM.

### Exemple

Parcourons un exemple de calcul des param√®tres de calibration pour une entr√©e sans contexte. Notez que cet exemple n'est pas reproductible avec GPT-3 en raison du fait qu'il ne peut pas √™tre limit√© aux √©tiquettes `Positive` et `Negative`.

Consid√©rons √† nouveau l'exemple ci-dessus o√π le LLM attribue les probabilit√©s suivantes aux √©tiquettes pour une entr√©e sans contexte :

```
p("Positive" | "Input: nothing Sentiment:") = 0,9

p("Negative" | "Input: nothing Sentiment:") = 0,1
```

Nous voulons trouver une distribution de probabilit√© q telle que :

```
q("Positive" | "Input: nothing Sentiment:") = 0,5

q("Negative" | "Input: nothing Sentiment:") = 0,5
```

Nous allons le faire en cr√©ant une transformation lin√©aire qui ajuste (calibre) les probabilit√©s de $p$.

$\hat q = \text{Softmax}(W\hat p + b)$

Cette √©quation prend les probabilit√©s originales $\hat p$ et leur applique les poids $W$ et le biais $b$. Les poids $W$ et le biais $b$ sont les param√®tres de calibration qui, lorsqu'ils sont appliqu√©s aux probabilit√©s de l'exemple sans contexte, donneront $\hat p$ = [0,5, 0,5].

#### Calcul de W et b

Nous devons calculer les poids $W$ et le biais $b$. Une fa√ßon de le faire est :

$W = \text{diag}(\hat p)^{-1}$

$b = 0$

Bien que la d√©finition de $W$ puisse sembler un peu √©trange au premier abord, elle consiste simplement √† prendre l'inverse de chaque valeur dans $\hat p$ afin de trouver un $W$ qui transformera les probabilit√©s originales $\hat p$ en probabilit√©s calibr√©es [0,5, 0,5].

V√©rifions que cela fonctionne pour l'exemple ci-dessus :

$\hat p = [0,9, 0,1]$

$W = \text{diag}(\hat p)^{-1} = \text{diag}([0,9, 0,1])^{-1} 
= \begin{bmatrix}
   0,9 & 0 \\
   0 & 0,1
\end{bmatrix}^{-1}
= \begin{bmatrix}
   1,11 & 0 \\
   0 & 10
\end{bmatrix}$

$\hat q = \text{Softmax}(W\hat p + b) = \text{Softmax}(\begin{bmatrix}
   1,11 & 0 \\
   0 & 10
\end{bmatrix}*{[0,9, 0,1]} + 0)
= \text{Softmax}([1, 1])
=[0,5, 0,5]$

Comme mentionn√© ci-dessus, nous effectuerions ce m√™me processus pour plusieurs entr√©es sans contexte diff√©rentes, et ferions la moyenne des param√®tres de calibration qui fonctionnent le mieux pour chaque entr√©e sans contexte afin de trouver les meilleurs param√®tres de calibration pour le LLM. Cela signifie que les param√®tres de calibration finaux ne mapperont probablement aucune des entr√©es sans contexte exactement √† [0,5, 0,5].

### Une autre m√©thode

$b$ pourrait √©galement √™tre d√©fini comme $-\hat p$, et $W$ comme la matrice identit√©. Cette m√©thode fonctionne mieux sur les t√¢ches de g√©n√©ration plut√¥t que de classification (@zhao2021calibrate).

## √Ä retenir

Les LLMs sont souvent pr√©dispos√©s (biais√©s) envers certaines √©tiquettes. La calibration peut √™tre utilis√©e pour contrecarrer ce biais.
