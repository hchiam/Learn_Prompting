export const metadata = {
  sidebar_position: 4,
  title: "üü¢ Cha√Æne de Pens√©e √† Z√©ro Exemple",
};

# üü¢ Cha√Æne de Pens√©e √† Z√©ro Exemple

La Cha√Æne de Pens√©e √† Z√©ro Exemple (Zero-shot-CoT) (@kojima2022large) est une
suite au <Term term="CoT prompting">prompting CoT</Term> (@wei2022chain), qui introduit un
prompt √† z√©ro exemple incroyablement simple. Ils constatent qu'en ajoutant les mots "**R√©fl√©chissons √©tape
par √©tape.**" √† la fin d'une question, les LLM sont capables de g√©n√©rer une cha√Æne de
pens√©e qui r√©pond √† la question. √Ä partir de cette cha√Æne de pens√©e, ils sont capables
d'extraire des r√©ponses plus pr√©cises.

<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/intermediate/zero_shot.webp"
    width={936}
    height={386}
    style={{ width: "500px", margin: "auto" }}
  />
</div>

<div style={{ textAlign: "center" }}>Cha√Æne de Pens√©e √† Z√©ro Exemple (Kojima et al.)</div>

Techniquement, le processus complet de Zero-shot-CoT implique deux prompts/compl√©tions s√©par√©s.
Dans l'image ci-dessous, la bulle sup√©rieure √† gauche g√©n√®re une cha√Æne de pens√©e, tandis que la bulle sup√©rieure √†
droite prend la sortie du premier prompt (y compris le premier prompt lui-m√™me),
et extrait la r√©ponse de la cha√Æne de pens√©e. Ce second prompt est un prompt _auto-augment√©_.

<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/intermediate/zero_shot_example.webp"
    width={1854}
    height={726}
    style={{ width: "500px", margin: "auto" }}
  />
</div>

<div style={{ textAlign: "center" }}>
  Processus complet de Cha√Æne de Pens√©e √† Z√©ro Exemple (Kojima et al.)
</div>

## Exemple

Voici quelques d√©monstrations (qui n'effectuent que l'extraction du raisonnement). Cette premi√®re
d√©mo montre GPT-3 (davinci-003) √©chouant √† une simple question de math√©matiques, tandis que la seconde d√©mo utilise un
prompt Zero-shot-CoT et r√©sout le probl√®me avec succ√®s. N'h√©sitez pas √† entrer votre
cl√© API OpenAI (Cliquez sur G√©n√©rer) et √† jouer avec les exemples. Notez √† quel point le prompt
Zero-shot-CoT est plus simple que le prompt CoT.

#### Incorrect

<iframe
  src="https://embed.learnprompting.org/embed?config=eyJ0b3BQIjoxLCJ0ZW1wZXJhdHVyZSI6MC43LCJtYXhUb2tlbnMiOjI1Niwib3V0cHV0IjoiSm9obiBoYXMgOCBwZWFycy4iLCJwcm9tcHQiOiJJZiBKb2huIGhhcyA1IHBlYXJzLCB0aGVuIGVhdHMgMiwgYW5kIGJ1eXMgNSBtb3JlLCB0aGVuIGdpdmVzIDMgdG8gaGlzIGZyaWVuZCwgaG93IG1hbnkgcGVhcnMgZG9lcyBoZSBoYXZlPyIsIm1vZGVsIjoidGV4dC1kYXZpbmNpLTAwMyJ9"
  style={{
    width: "100%",
    height: "500px",
    border: "0",
    borderRadius: "4px",
    overflow: "hidden",
  }}
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>

#### Correct

<iframe
  src="https://embed.learnprompting.org/embed?config=eyJ0b3BQIjoxLCJ0ZW1wZXJhdHVyZSI6MC43LCJtYXhUb2tlbnMiOjI1Niwib3V0cHV0IjoiSm9obiBzdGFydHMgd2l0aCA1IHBlYXJzLiBIZSBlYXRzIDIgcGVhcnMsIGxlYXZpbmcgaGltIHdpdGggMyBwZWFycy4gSGUgYnV5cyA1IG1vcmUgcGVhcnMsIGdpdmluZyBoaW0gYSB0b3RhbCBvZiA4IHBlYXJzLiBIZSBnaXZlcyAzIHBlYXJzIHRvIGhpcyBmcmllbmQsIGxlYXZpbmcgaGltIHdpdGggb25seSA1IHBlYXJzLiIsInByb21wdCI6IklmIEpvaG4gaGFzIDUgcGVhcnMsIHRoZW4gZWF0cyAyLCBhbmQgYnV5cyA1IG1vcmUsIHRoZW4gZ2l2ZXMgMyB0byBoaXMgZnJpZW5kLCBob3cgbWFueSBwZWFycyBkb2VzIGhlIGhhdmU%2FXG5cbkxldCdzIHRoaW5rIHN0ZXAgYnkgc3RlcC4iLCJtb2RlbCI6InRleHQtZGF2aW5jaS0wMDMifQ%3D%3D"
  style={{
    width: "100%",
    height: "500px",
    border: "0",
    borderRadius: "4px",
    overflow: "hidden",
  }}
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>

## R√©sultats

La Cha√Æne de Pens√©e √† Z√©ro Exemple a √©galement √©t√© efficace pour am√©liorer les r√©sultats sur les t√¢ches d'arithm√©tique, de bon sens et de raisonnement symbolique. Cependant, sans surprise, elle n'√©tait g√©n√©ralement pas aussi efficace que le prompting CoT. Un cas d'utilisation important pour la Cha√Æne de Pens√©e √† Z√©ro Exemple est lorsqu'il est difficile d'obtenir des exemples pour le prompting CoT.

## Ablations d'Int√©r√™t

Kojima et al. ont exp√©riment√© un certain nombre de prompts diff√©rents pour la Cha√Æne de Pens√©e √† Z√©ro Exemple (par exemple, "R√©solvons ce probl√®me en le divisant en √©tapes." ou "R√©fl√©chissons √† cela de mani√®re logique."), mais ils ont constat√© que "R√©fl√©chissons √©tape par √©tape" √©tait le plus efficace pour les t√¢ches qu'ils avaient choisies.

## Notes

L'√©tape d'extraction doit souvent √™tre sp√©cifique √† la t√¢che, ce qui rend la Cha√Æne de Pens√©e √† Z√©ro Exemple moins g√©n√©ralisable qu'elle ne le para√Æt au premier abord.

De mani√®re anecdotique, j'ai constat√© que les prompts de style Cha√Æne de Pens√©e √† Z√©ro Exemple sont parfois efficaces pour am√©liorer la longueur des compl√©tions pour les t√¢ches g√©n√©ratives. Par exemple, consid√©rez le prompt standard `√âcrivez une histoire sur une grenouille et un champignon qui deviennent amis.` Ajouter les mots `R√©fl√©chissons √©tape par √©tape.` √† la fin de ce prompt conduit √† une compl√©tion beaucoup plus longue.
