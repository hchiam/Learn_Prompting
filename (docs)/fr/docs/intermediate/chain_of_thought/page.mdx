export const metadata = {
  sidebar_position: 3,
  locale: "fr-fr",
  style: "chicago",
  title: "üü¢ Prompting par Cha√Æne de Pens√©e",
};

# üü¢ Prompting par Cha√Æne de Pens√©e

Le prompting par Cha√Æne de Pens√©e (Chain of Thought - CoT) (@wei2022chain) est une m√©thode de prompting r√©cemment d√©velopp√©e qui encourage le LLM √† expliquer son raisonnement. L'image ci-dessous (@wei2022chain) montre un <Term term="few shot standard prompt">prompt standard √† quelques exemples</Term> (√† gauche) compar√© √† un prompt par cha√Æne de pens√©e (√† droite).

<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/basics/chain_of_thought_example.webp"
    width={1788}
    height={900}
    style={{ width: "750px", margin: "auto" }}
  />
</div>

<div style={{ textAlign: "center" }}>Prompting R√©gulier vs CoT (Wei et al.)</div>

L'id√©e principale du CoT est que, en montrant au LLM quelques <Term term="exemplars">exemples</Term> o√π le processus de raisonnement est expliqu√© dans les exemples, le LLM montrera √©galement le processus de raisonnement lorsqu'il r√©pondra au prompt. Cette explication du raisonnement conduit souvent √† des r√©sultats plus pr√©cis.

## Exemple

Voici quelques d√©monstrations. La premi√®re montre GPT-3 (davinci-003)
√©chouant √† r√©soudre un simple probl√®me de mots. La seconde montre GPT-3 (davinci-003) r√©solvant avec succ√®s le m√™me probl√®me, en utilisant le prompting par Cha√Æne de Pens√©e.

#### Incorrect

<iframe
  src="https://embed.learnprompting.org/embed?config=eyJ0b3BQIjowLCJ0ZW1wZXJhdHVyZSI6MCwibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6Ik9wdGlvbiAxIGlzIGEgZmFzdGVyIHdheSB0byBnZXQgdG8gd29yay4iLCJwcm9tcHQiOiJXaGljaCBpcyBhIGZhc3RlciB3YXkgdG8gZ2V0IHRvIHdvcms%2FXG5PcHRpb24gMTogVGFrZSBhIDEwMDAgbWludXRlIGJ1cywgdGhlbiBhIGhhbGYgaG91ciB0cmFpbiwgYW5kIGZpbmFsbHkgYSAxMCBtaW51dGUgYmlrZSByaWRlLlxuT3B0aW9uIDI6IFRha2UgYW4gODAwIG1pbnV0ZSBidXMsIHRoZW4gYW4gaG91ciB0cmFpbiwgYW5kIGZpbmFsbHkgYSAzMCBtaW51dGUgYmlrZSByaWRlLiIsIm1vZGVsIjoidGV4dC1kYXZpbmNpLTAwMyJ9"
  style={{
    width: "100%",
    height: "500px",
    border: "0",
    borderRadius: "4px",
    overflow: "hidden",
  }}
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>

#### Correct

<iframe
  src="https://embed.learnprompting.org/embed?config=eyJ0b3BQIjowLCJ0ZW1wZXJhdHVyZSI6MCwibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6Ik9wdGlvbiAxIHdpbGwgdGFrZSAxMDAwKzMwKzEwID0gMTA0MCBtaW51dGVzLlxuT3B0aW9uIDIgd2lsbCB0YWtlIDgwMCs2MCszMCA9IDg5MCBtaW51dGVzLlxuU2luY2UgT3B0aW9uIDIgdGFrZXMgODkwIG1pbnV0ZXMgYW5kIE9wdGlvbiAxIHRha2VzIDEwNDAgbWludXRlcywgT3B0aW9uIDIgaXMgZmFzdGVyLiIsInByb21wdCI6IldoaWNoIGlzIGEgZmFzdGVyIHdheSB0byBnZXQgaG9tZT9cbk9wdGlvbiAxOiBUYWtlIGFuIDEwIG1pbnV0ZXMgYnVzLCB0aGVuIGFuIDQwIG1pbnV0ZSBidXMsIGFuZCBmaW5hbGx5IGEgMTAgbWludXRlIHRyYWluLlxuT3B0aW9uIDI6IFRha2UgYSA5MCBtaW51dGVzIHRyYWluLCB0aGVuIGEgNDUgbWludXRlIGJpa2UgcmlkZSwgYW5kIGZpbmFsbHkgYSAxMCBtaW51dGUgYnVzLlxuT3B0aW9uIDEgd2lsbCB0YWtlIDEwKzQwKzEwID0gNjAgbWludXRlcy5cbk9wdGlvbiAyIHdpbGwgdGFrZSA5MCs0NSsxMD0xNDUgbWludXRlcy5cblNpbmNlIE9wdGlvbiAxIHRha2VzIDYwIG1pbnV0ZXMgYW5kIE9wdGlvbiAyIHRha2VzIDE0NSBtaW51dGVzLCBPcHRpb24gMSBpcyBmYXN0ZXIuXG5cbldoaWNoIGlzIGEgZmFzdGVyIHdheSB0byBnZXQgdG8gd29yaz9cbk9wdGlvbiAxOiBUYWtlIGEgMTAwMCBtaW51dGUgYnVzLCB0aGVuIGEgaGFsZiBob3VyIHRyYWluLCBhbmQgZmluYWxseSBhIDEwIG1pbnV0ZSBiaWtlIHJpZGUuXG5PcHRpb24gMjogVGFrZSBhbiA4MDAgbWludXRlIGJ1cywgdGhlbiBhbiBob3VyIHRyYWluLCBhbmQgZmluYWxseSBhIDMwIG1pbnV0ZSBiaWtlIHJpZGUuIiwibW9kZWwiOiJ0ZXh0LWRhdmluY2ktMDAzIn0%3D"
  style={{
    width: "100%",
    height: "500px",
    border: "0",
    borderRadius: "4px",
    overflow: "hidden",
  }}
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>

## R√©sultats

Il a √©t√© d√©montr√© que le CoT est efficace pour am√©liorer les r√©sultats sur des t√¢ches comme
l'arithm√©tique, le sens commun et les t√¢ches de raisonnement symbolique (@wei2022chain).
En particulier, PaLM 540B avec prompting (@chowdhery2022palm) atteint un taux de pr√©cision de r√©solution de 57% sur GSM8K(@cobbe2021training) (√©tat de l'art √† l'√©poque).

<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/intermediate/prompted_palm.webp"
    width={798}
    height={774}
    style={{ width: "300px", margin: "auto" }}
  />
</div>

<div style={{ textAlign: "center" }}>
  Comparaison des mod√®les sur le benchmark GSM8K (Wei et al.)
</div>

## Limitations

Il est important de noter que, selon Wei et al., "le CoT n'apporte des gains de performance que lorsqu'il est utilis√© avec des mod√®les d'environ 100 milliards de param√®tres". Les mod√®les plus petits ont √©crit des cha√Ænes de pens√©e illogiques, ce qui a conduit √† une pr√©cision inf√©rieure √† celle du prompting standard. Les mod√®les obtiennent g√©n√©ralement des am√©liorations de performance gr√¢ce au prompting CoT de mani√®re proportionnelle √† la taille du mod√®le.

## Notes

Aucun mod√®le de langage n'a √©t√© ~~bless√©~~ affin√© pendant la r√©daction de ce chapitre üòä.
