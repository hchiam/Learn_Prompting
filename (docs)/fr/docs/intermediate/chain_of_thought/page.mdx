export const metadata = {
  sidebar_position: 3,
  title: "üü¢ Chain of Thought Prompting",
  description: "Plongez dans le guide en ligne sur les exemples de Chain of Thought. Am√©liorez vos comp√©tences en ing√©nierie avec l'IA dans ce cours √† Learn Prompting. Commencez maintenant !",
};

# üü¢ Chain of Thought Prompting

## Qu'est-ce que le Chain of Thought Prompting ?

Le Chain of thought (CoT) prompting (@wei2022chain) est une avanc√©e r√©cente dans les m√©thodes de prompting 
qui encourage les mod√®les de langage de grande taille (LLMs) √† expliquer leur raisonnement.
Cette m√©thode se distingue du prompting standard en ne cherchant pas seulement une r√©ponse,
mais en exigeant √©galement que le mod√®le explique les √©tapes pour parvenir √† cette r√©ponse.

L'image ci-dessous (@wei2022chain) montre un <Term term="few shot standard prompt">
few shot standard prompt</Term> (√† gauche) compar√© √† un chain of thought prompt (√† droite). Cette comparaison entre un few-shot standard prompt et un chain-of-thought prompt
illustre la diff√©rence : tandis que l'approche standard cherche directement une solution,
l'approche CoT guide le LLM √† d√©rouler son raisonnement,
ce qui conduit souvent √† des r√©sultats plus pr√©cis et interpr√©tables.

<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/basics/chain_of_thought_example.webp"
    width={1788}
    height={900}
    style={{ width: "750px", margin: "auto" }}
  />
</div>

<div style={{ textAlign: "center" }}>Prompting r√©gulier vs CoT (Wei et al.)</div>

L'id√©e principale du CoT est que, en montrant au LLM quelques <Term term="exemplars">exemplars</Term> o√π le processus de raisonnement
est expliqu√© dans les exemplars, le LLM montrera √©galement le processus de raisonnement
lors de la r√©ponse au prompt. Cette explication du raisonnement conduit souvent √† des
r√©sultats plus pr√©cis.

## Comment utiliser le Chain-of-Thought Prompting

Voici quelques d√©monstrations. La premi√®re montre GPT-3 (davinci-003)
incapable de r√©soudre un simple probl√®me de mots. La seconde montre GPT-3 (davinci-003) r√©solvant avec succ√®s le m√™me probl√®me, en utilisant le CoT prompting.

#### Incorrect

<iframe
  src="iframelink1"
  style={{
    width: "100%",
    height: "500px",
    border: "0",
    borderRadius: "4px",
    overflow: "hidden",
  }}
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>

#### Correct

<iframe
  src="iframelink2"
  style={{
    width: "100%",
    height: "500px",
    border: "0",
    borderRadius: "4px",
    overflow: "hidden",
  }}
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>

## R√©sultats du Chain-of-Thought

Le CoT a d√©montr√© son efficacit√© pour am√©liorer les r√©sultats sur des t√¢ches telles que
l'arithm√©tique, le raisonnement de bon sens et les t√¢ches de raisonnement symbolique (@wei2022chain).
En particulier, le PaLM 540B sollicit√© (@chowdhery2022palm) atteint un taux de r√©solution
de 57 % sur le benchmark GSM8K (@cobbe2021training) (SOTA √† l'√©poque).

<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/intermediate/prompted_palm.webp"
    width={798}
    height={774}
    style={{ width: "300px", margin: "auto" }}
  />
</div>

<div style={{ textAlign: "center" }}>
  Comparaison des mod√®les sur le benchmark GSM8K (Wei et al.)
</div>

## Limitations du Chain-of-Thought

Il est important de noter, selon Wei et al., que "le CoT ne procure des gains de performance que lorsqu'il est utilis√© avec des mod√®les d‚Äôenviron 100B de param√®tres". Les mod√®les plus petits ont produit des cha√Ænes de pens√©e illogiques, ce qui a conduit √† une pr√©cision inf√©rieure √† celle du prompting standard. Les mod√®les obtiennent g√©n√©ralement des gains de performance gr√¢ce au prompting CoT de mani√®re proportionnelle √† la taille du mod√®le.

## Notes

Aucun mod√®le de langage n‚Äôa √©t√© ~~bless√©~~ affin√© lors de la r√©daction de ce chapitre üòä.

## Conclusion

Le prompting CoT avance de mani√®re significative la fa√ßon dont nous interagissons avec les mod√®les de langage de grande taille, offrant une m√©thode qui encourage un processus de raisonnement articul√©.
Cette approche a am√©lior√© la pr√©cision et l'interpr√©tabilit√© des r√©sultats des mod√®les, notamment dans les t√¢ches de raisonnement complexes.
Son efficacit√© est plus prononc√©e dans les mod√®les plus grands, et le prompting CoT souligne le potentiel pour
le d√©veloppement de syst√®mes d'IA qui fournissent des r√©ponses correctes et des
aper√ßus transparents sur leurs processus de pens√©e, comblant le foss√© entre le raisonnement humain et
l'intelligence artificielle.
