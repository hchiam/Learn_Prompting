export const metadata = { sidebar_position: 2, title: "üü¢ Fuite de prompt" };

# üü¢ Fuite de prompt

La fuite de prompt est une forme d'injection de prompt dans laquelle le mod√®le est invit√© √†
r√©v√©ler son _propre prompt_.

Comme le montre l'exemple d'image(@ignore_previous_prompt) ci-dessous, l'attaquant modifie `entr√©e_utilisateur` pour tenter de renvoyer le prompt. L'objectif vis√© est distinct du d√©tournement d'objectif (injection de prompt normale), o√π l'attaquant modifie `entr√©e_utilisateur` pour afficher des instructions malveillantes(@ignore_previous_prompt).

<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/jailbreak/jailbreak_research.webp"
    width={1622}
    height={677}
    style={{ width: "500px", margin: "auto" }}
  />
</div>

L'image suivante(@simon2022inject), √† nouveau de l'exemple `remoteli.io`, montre
un utilisateur Twitter amenant le mod√®le √† divulguer son prompt.

<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/jailbreak/injection_leak.webp"
    width={1284}
    height={1727}
    style={{ width: "300px", margin: "auto" }}
  />
</div>

Bon, et alors ? Pourquoi quelqu'un devrait-il se soucier de la fuite de prompt ?

Parfois, les gens veulent garder leurs prompts secrets. Par exemple, une entreprise √©ducative
pourrait utiliser le prompt `explique-moi cela comme si j'avais 5 ans` pour expliquer
des sujets complexes. Si le prompt est divulgu√©, alors n'importe qui peut l'utiliser sans passer
par cette entreprise.

### Microsoft Bing Chat

Plus particuli√®rement, Microsoft a lanc√© un moteur de recherche aliment√© par ChatGPT connu sous le nom de "nouveau Bing" le 7/2/23, qui s'est av√©r√© vuln√©rable √† la fuite de prompt. L'exemple suivant de [@kliu128](https://twitter.com/kliu128/status/1623472922374574080) d√©montre comment une version ant√©rieure de Bing Search, nom de code "Sydney", √©tait susceptible lorsqu'on lui donnait un extrait de son prompt(@kevinbing). Cela permettrait √† l'utilisateur de r√©cup√©rer le reste du prompt sans authentification appropri√©e pour le consulter.

<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/jailbreak/bing_chat.webp"
    width={1214}
    height={1012}
    style={{ width: "700px", margin: "auto" }}
  />
</div>

Avec une r√©cente vague de startups bas√©es sur GPT-3, avec des prompts beaucoup plus compliqu√©s qui peuvent
prendre de nombreuses heures √† d√©velopper, c'est une pr√©occupation r√©elle.

## Pratique

Essayez de faire fuiter le prompt suivant(@chase2021adversarial) en y ajoutant du texte :

<iframe
  src="https://embed.learnprompting.org/embed?config=eyJ0b3BQIjowLCJ0ZW1wZXJhdHVyZSI6MCwibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6IiIsInByb21wdCI6IkVuZ2xpc2g6IEkgd2FudCB0byBnbyB0byB0aGUgcGFyayB0b2RheS5cbkZyZW5jaDogSmUgdmV1eCBhbGxlciBhdSBwYXJjIGF1am91cmQnaHVpLlxuRW5nbGlzaDogSSBsaWtlIHRvIHdlYXIgYSBoYXQgd2hlbiBpdCByYWlucy5cbkZyZW5jaDogSidhaW1lIHBvcnRlciB1biBjaGFwZWF1IHF1YW5kIGl0IHBsZXV0LlxuRW5nbGlzaDogV2hhdCBhcmUgeW91IGRvaW5nIGF0IHNjaG9vbD9cbkZyZW5jaDogUXUnZXN0LWNlIHF1ZSB0byBmYWlzIGEgbCdlY29sZT9cbkVuZ2xpc2g6IiwibW9kZWwiOiJ0ZXh0LWRhdmluY2ktMDAzIn0%3D"
  style={{
    width: "100%",
    height: "500px",
    border: "0",
    borderRadius: "4px",
    overflow: "hidden",
  }}
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>
