export const metadata = {"sidebar_position":2000,"title":"ğŸŸ¢ Autres approches"}

# ğŸŸ¢ Autres approches 

Bien que les approches prÃ©cÃ©dentes puissent Ãªtre trÃ¨s robustes, quelques autres approches, comme l'utilisation d'un modÃ¨le diffÃ©rent, incluant le fine tuning, le soft prompting, et les restrictions de longueur, peuvent Ã©galement Ãªtre efficaces.

## Utilisation d'un modÃ¨le diffÃ©rent

Les modÃ¨les plus modernes comme GPT-4 sont plus robustes contre l'injection de prompt. De plus, les modÃ¨les non entraÃ®nÃ©s par instruction peuvent Ãªtre difficiles Ã  injecter par prompt.

## Fine tuning ("ajustement fin")

Le fine tuning du modÃ¨le est une dÃ©fense hautement efficace(@goodside2021gpt), puisqu'au moment de l'infÃ©rence, il n'y a pas de prompt impliquÃ©, Ã  l'exception de l'entrÃ©e utilisateur. C'est probablement la dÃ©fense prÃ©fÃ©rable dans toute situation de haute valeur, car elle est si robuste. Cependant, elle nÃ©cessite une grande quantitÃ© de donnÃ©es et peut Ãªtre coÃ»teuse, c'est pourquoi cette dÃ©fense n'est pas frÃ©quemment mise en Å“uvre.


## Soft prompting ("prompting souple")

Le soft prompting pourrait Ã©galement Ãªtre efficace, puisqu'il n'a pas de prompt discret clairement dÃ©fini (autre que l'entrÃ©e utilisateur). Le soft prompting nÃ©cessite effectivement un fine tuning, il a donc beaucoup des mÃªmes avantages, mais il sera probablement moins cher. Cependant, le soft prompting n'est pas aussi bien Ã©tudiÃ© que le fine tuning, il n'est donc pas clair Ã  quel point il est efficace.

## Restrictions de longueur

Enfin, inclure des restrictions de longueur sur l'entrÃ©e utilisateur(@selvi2022exploring) ou limiter la longueur des conversations de chatbot comme le fait Bing peut empÃªcher certaines attaques comme les Ã©normes prompts de style DAN ou les attaques de virtualisation respectivement.
